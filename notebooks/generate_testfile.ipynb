{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b954b40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "import h5py\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1eb8b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 1265657\n",
      "Saving 109C.TA_20060723155859_EV -> shape (6000, 3), dtype float32\n",
      "Saving 109C.TA_20061103155652_EV -> shape (6000, 3), dtype float32\n",
      "Saving 109C.TA_20061103161223_EV -> shape (6000, 3), dtype float32\n",
      "Saving 109C.TA_20061114133221_EV -> shape (6000, 3), dtype float32\n",
      "Saving 109C.TA_20061127104640_EV -> shape (6000, 3), dtype float32\n",
      "Saved 5 .wav files to ../earthquake_wavs\n"
     ]
    }
   ],
   "source": [
    "HDF5_PATH = \"../data/merge.hdf5\"\n",
    "OUTPUT_DIR = \"../earthquake_wavs\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "FS = 100\n",
    "\n",
    "\n",
    "with h5py.File(HDF5_PATH, 'r') as f:\n",
    "    all_keys = list(f['data'].keys())\n",
    "    print(f\"Total samples: {len(all_keys)}\")\n",
    "\n",
    "    for key in all_keys[:5]:\n",
    "        waveform = f['data'][key][()]\n",
    "        \n",
    "        print(f\"Saving {key} -> shape {waveform.shape}, dtype {waveform.dtype}\")\n",
    "\n",
    "        sf.write(\n",
    "            os.path.join(OUTPUT_DIR, f\"{key}.wav\"),\n",
    "            waveform,\n",
    "            FS,\n",
    "            subtype='FLOAT'\n",
    "        )\n",
    "\n",
    "print(f\"Saved {min(5, len(all_keys))} .wav files to {OUTPUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6ea704a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 6 noise .wav files in ../noise_wavs\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import h5py\n",
    "import os\n",
    "import soundfile as sf\n",
    "\n",
    "HDF5_PATH = \"../data/merge.hdf5\"\n",
    "LABEL_PATH = \"../preprocessed/key_to_label.pkl\"\n",
    "OUTPUT_DIR = \"../noise_wavs\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "FS = 100\n",
    "\n",
    "\n",
    "with open(LABEL_PATH, \"rb\") as f:\n",
    "  key_to_label = pickle.load(f)\n",
    "\n",
    "\n",
    "with h5py.File(HDF5_PATH, \"r\") as f:\n",
    "  count = 0\n",
    "  for key, label in key_to_label.items():\n",
    "    if label == 0:  # Noise sample\n",
    "      waveform = f[\"data\"][key][()]\n",
    "      sf.write(os.path.join(OUTPUT_DIR, f\"{key}.wav\"), waveform, FS)\n",
    "      count += 1\n",
    "      if count >= 6:\n",
    "        break\n",
    "\n",
    "print(f\"Saved {count} noise .wav files in {OUTPUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cc7213e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../preprocessed/key_to_label.pkl\", \"rb\") as f:\n",
    "    key_to_label = pickle.load(f)\n",
    "\n",
    "with open(\"../preprocessed/station_to_keys.pkl\", \"rb\") as f:\n",
    "    station_to_keys = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e607414d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../data/merge.hdf5\"\n",
    "\n",
    "\n",
    "hdf5_file = h5py.File(file_path, 'r')\n",
    "data_group = hdf5_file['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43e85f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ANON.AV_20180116000618_NO', 'ARK1.7F_20100726193148_NO',\n",
       "       'ANPB.AV_20180115192448_NO', ..., 'AUCH.AV_20180115215930_NO',\n",
       "       'AC02.C1_201511091043_NO', 'AC04.C1_201505021244_NO'], dtype='<U25')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_keys = np.load(\"../preprocessed/noise_keys.npy\")\n",
    "noise_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e521b257",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = list(station_to_keys.keys())\n",
    "random.seed(40)\n",
    "random.shuffle(stations)\n",
    "\n",
    "n_total = len(stations)\n",
    "n_train = int(0.8 * n_total)\n",
    "n_val = int(0.1 * n_total)\n",
    "\n",
    "train_stations = stations[:n_train]\n",
    "val_stations = stations[n_train:n_train + n_val]\n",
    "test_stations = stations[n_train + n_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d741824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55266, 2)\n",
      "(7420, 2)\n",
      "(7314, 2)\n"
     ]
    }
   ],
   "source": [
    "def collect_samples(station_list):\n",
    "  return np.array([\n",
    "    (key, key_to_label[key])\n",
    "    for st in station_list\n",
    "    for key in station_to_keys[st]\n",
    "  ], dtype=object)\n",
    "\n",
    "train_samples = collect_samples(train_stations)\n",
    "val_samples   = collect_samples(val_stations)\n",
    "test_samples  = collect_samples(test_stations)\n",
    "\n",
    "print(train_samples.shape)\n",
    "print(val_samples.shape)\n",
    "print(test_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4be5b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_keys(samples):\n",
    "  arr = []\n",
    "  for sample in samples:\n",
    "    arr.append(sample[0])\n",
    "  \n",
    "  return arr\n",
    "\n",
    "test_keys = get_sample_keys(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a85a88c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 1265657\n",
      "Saving ACTO.PO_200909062326_NO -> shape (6000, 3), dtype float32\n",
      "Saving ACTO.PO_201104201236_NO -> shape (6000, 3), dtype float32\n",
      "Saving ACTO.PO_201010190456_NO -> shape (6000, 3), dtype float32\n",
      "Saving ACTO.PO_201307140923_NO -> shape (6000, 3), dtype float32\n",
      "Saving ACTO.PO_201101161500_NO -> shape (6000, 3), dtype float32\n",
      "Saving ACTO.PO_201303091104_NO -> shape (6000, 3), dtype float32\n",
      "Saving ACTO.PO_201005200512_NO -> shape (6000, 3), dtype float32\n",
      "Saved 7 .wav files to ../test_wavs\n"
     ]
    }
   ],
   "source": [
    "HDF5_PATH = \"../data/merge.hdf5\"\n",
    "OUTPUT_DIR = \"../test_wavs\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "FS = 100\n",
    "\n",
    "\n",
    "with h5py.File(HDF5_PATH, 'r') as f:\n",
    "    all_keys = list(f['data'].keys())\n",
    "    print(f\"Total samples: {len(all_keys)}\")\n",
    "    count = 0\n",
    "    for key in test_keys:\n",
    "        waveform = f['data'][key][()]\n",
    "        print(f\"Saving {key} -> shape {waveform.shape}, dtype {waveform.dtype}\")\n",
    "\n",
    "        sf.write(\n",
    "            os.path.join(OUTPUT_DIR, f\"{key}.wav\"),\n",
    "            waveform,\n",
    "            FS,\n",
    "            subtype='FLOAT'\n",
    "        )\n",
    "        count += 1\n",
    "        \n",
    "        if count > 6:\n",
    "            break\n",
    "\n",
    "print(f\"Saved {count} .wav files to {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e950ea24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(key_to_label['ACTO.PO_200909062326_NO'])\n",
    "print(key_to_label['ACTO.PO_201104201236_NO'])\n",
    "print(key_to_label['ACTO.PO_201010190456_NO'])\n",
    "print(key_to_label['ACTO.PO_201307140923_NO'])\n",
    "print(key_to_label['ACTO.PO_201101161500_NO'])\n",
    "print(key_to_label['ACTO.PO_201303091104_NO'])\n",
    "print(key_to_label['ACTO.PO_201005200512_NO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbac9b35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf210",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
